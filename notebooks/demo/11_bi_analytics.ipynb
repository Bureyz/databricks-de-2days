{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "053bbad4-7d29-454f-b690-decad6246012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# BI & Analytics Integrations\n",
    "\n",
    "**Training Objective:** Integrating Databricks Lakehouse with BI tools and sharing data with business users\n",
    "\n",
    "**Topics Covered:**\n",
    "- SQL Warehouses: Serverless, Pro, Classic\n",
    "- Databricks Genie (AI/BI) - natural language queries\n",
    "- External Integrations: Power BI, Dremio\n",
    "- Preparing data for BI layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f9d0a6-8c62-4b59-a5c3-578fdc9e8034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Theoretical Introduction\n",
    "\n",
    "**Section Objective:** Understand how to share data from Lakehouse to the external world and business users.\n",
    "\n",
    "**Basic Concepts:**\n",
    "- **SQL Warehouse**: Optimized compute engine for SQL queries (not for Python/Scala code).\n",
    "- **Genie**: Intelligent data assistant that understands table structure and answers natural language questions.\n",
    "- **Direct Lake**: Power BI connection mode that reads Parquet files directly, bypassing SQL layer (fastest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5486d7b5-d237-4aa2-8d42-1f073fb8c76d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## User Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9234e35-8d7f-4f25-bf74-4d670e2570f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac8b1f4-51f1-4169-bed2-754c62f24bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1069beeb-31fe-471e-ab4c-866e9a5816f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Set catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {GOLD_SCHEMA}\")\n",
    "\n",
    "display(spark.createDataFrame([\n",
    "    (\"Catalog\", CATALOG),\n",
    "    (\"Schema\", GOLD_SCHEMA)\n",
    "], [\"Parameter\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77a91f6-1107-47df-a057-108f3c98e664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Databricks SQL Warehouses\n",
    "\n",
    "SQL Warehouses are the \"heart\" of the BI layer in Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5a6a3aa-7ddc-4ca1-a44d-e07766ca590e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Warehouse Types\n",
    "\n",
    "1. **Serverless**: Starts in seconds, scales automatically. Recommended.\n",
    "2. **Pro**: Uses the Photon engine but requires longer startup time (unless a pool is used).\n",
    "3. **Classic**: Older architecture (VM-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29fefb7c-cfee-4dd4-8e66-78fcc8898227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example Warehouse configuration definition (JSON)\n",
    "# This can be used in the Databricks API to automate creation\n",
    "\n",
    "warehouse_config = {\n",
    "    \"name\": \"Warehouse_Demo\",\n",
    "    \"cluster_size\": \"2X-Small\",\n",
    "    \"min_num_clusters\": 1,\n",
    "    \"max_num_clusters\": 2,\n",
    "    \"auto_stop_mins\": 10,\n",
    "    \"enable_serverless_compute\": True,\n",
    "    \"warehouse_type\": \"PRO\",\n",
    "    \"tags\": {\n",
    "        \"department\": \"Sales\",\n",
    "        \"cost_center\": \"1234\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display configuration as DataFrame\n",
    "config_df = spark.createDataFrame([\n",
    "    (\"name\", warehouse_config[\"name\"]),\n",
    "    (\"cluster_size\", warehouse_config[\"cluster_size\"]),\n",
    "    (\"min_num_clusters\", str(warehouse_config[\"min_num_clusters\"])),\n",
    "    (\"max_num_clusters\", str(warehouse_config[\"max_num_clusters\"])),\n",
    "    (\"auto_stop_mins\", str(warehouse_config[\"auto_stop_mins\"])),\n",
    "    (\"enable_serverless_compute\", str(warehouse_config[\"enable_serverless_compute\"])),\n",
    "    (\"warehouse_type\", warehouse_config[\"warehouse_type\"]),\n",
    "    (\"tags.department\", warehouse_config[\"tags\"][\"department\"]),\n",
    "    (\"tags.cost_center\", warehouse_config[\"tags\"][\"cost_center\"])\n",
    "], [\"Parameter\", \"Value\"])\n",
    "\n",
    "display(config_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e186b1a2-ec5e-45db-9574-1461af9e4d3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Databricks Genie (AI/BI)\n",
    "\n",
    "Genie allows asking questions to data without knowing SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14a009bf-7fef-48f0-bdab-c6f3286519a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Preparing Data for Genie\n",
    "\n",
    "For Genie to work well, we need to ensure metadata (comments on tables and columns) is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee7d21a9-e5f5-4e8e-a7af-dcb3d6d042ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Add comments to the Gold table and the correct column\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    COMMENT ON TABLE {CATALOG}.{GOLD_SCHEMA}.fact_sales IS \n",
    "    'Fact table containing sales transactions. Contains amounts, dates, and foreign keys to dimensions.'\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    COMMENT ON COLUMN {CATALOG}.{GOLD_SCHEMA}.fact_sales.net_amount IS \n",
    "    'Total order value in PLN (gross).'\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    spark.createDataFrame(\n",
    "        [\n",
    "            (\"Metadata\", \"Updated\"),\n",
    "            (\"Goal\", \"Genie will now better understand this data\")\n",
    "        ],\n",
    "        [\"Status\", \"Value\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7176ff-b998-4d3d-8ad4-cb513a681584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## External Integrations (Power BI & Iceberg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fd01e92-e201-4114-998a-c9a9a2e3205d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Power BI - Direct Lake vs Direct Query\n",
    "\n",
    "- **Direct Lake**: Power BI Service -> OneLake/Storage (Parquet). Requires Fabric or appropriate configuration.\n",
    "- **Direct Query**: Power BI -> SQL Warehouse -> Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f93f41d-d34d-482f-ad84-4c415197035f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Unity Catalog Iceberg Endpoint\n",
    "\n",
    "**Dremio** connects to Databricks via the **Unity Catalog Iceberg REST Catalog endpoint**. \n",
    "This requires enabling **UniForm (Iceberg reads)** on Delta tables.\n",
    "\n",
    "#### How it works?\n",
    "\n",
    "```\n",
    "Dremio → Unity Catalog (Iceberg REST API) → Delta Table with UniForm → Parquet files\n",
    "```\n",
    "\n",
    "Delta Lake and Iceberg use the same Parquet files - UniForm only generates additional Iceberg metadata without copying data.\n",
    "\n",
    "#### Requirements:\n",
    "1. Table registered in **Unity Catalog** (managed or external)\n",
    "2. **Column mapping** enabled (`delta.columnMapping.mode = 'name'`)\n",
    "3. **Databricks Runtime 14.3 LTS+** for writing\n",
    "4. Table **without deletion vectors** (or use REORG to remove them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "564ae2c0-4b35-42d2-ad4e-95ccb7774c5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Enable UniForm when creating a new table\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{GOLD_SCHEMA}.fact_sales_iceberg\n",
    "TBLPROPERTIES (\n",
    "    'delta.columnMapping.mode' = 'name',\n",
    "    'delta.enableIcebergCompatV2' = 'true',\n",
    "    'delta.universalFormat.enabledFormats' = 'iceberg'\n",
    ")\n",
    "AS SELECT * FROM {CATALOG}.{GOLD_SCHEMA}.fact_sales\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c72a13ce-6231-49b9-9e3f-694a1b781862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Enable UniForm on an existing table (ALTER TABLE)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {CATALOG}.{GOLD_SCHEMA}.dim_customer SET TBLPROPERTIES (\n",
    "    'delta.columnMapping.mode' = 'name',\n",
    "    'delta.enableIcebergCompatV2' = 'true',\n",
    "    'delta.universalFormat.enabledFormats' = 'iceberg'\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88724705-374d-495f-8162-365015f18470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: If the table has Deletion Vectors - use REORG\n",
    "# REORG removes deletion vectors and enables UniForm in one step\n",
    "\n",
    "# spark.sql(f\"\"\"\n",
    "# REORG TABLE {CATALOG}.{GOLD_SCHEMA}.fact_sales \n",
    "# APPLY (UPGRADE UNIFORM(ICEBERG_COMPAT_VERSION=2))\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86097be9-333f-45f5-954a-8c934459daad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Check Iceberg metadata generation status\n",
    "\n",
    "result = spark.sql(f\"DESCRIBE EXTENDED {CATALOG}.{GOLD_SCHEMA}.dim_customer\")\n",
    "display(result.filter(\"col_name LIKE '%iceberg%' OR col_name LIKE '%uniform%' OR col_name LIKE '%converted%'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6855fc2-0c68-47a4-90c2-8e9952916ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Dremio Configuration - Unity Catalog Iceberg REST\n",
    "\n",
    "Dremio connects via **Iceberg REST Catalog API** - **does NOT require SQL Warehouse**.\n",
    "\n",
    "| Connection | SQL Warehouse? | How it works |\n",
    "|------------|----------------|------------|\n",
    "| Power BI / Tableau (JDBC) | YES | Queries via SQL Warehouse |\n",
    "| Dremio / Snowflake / Trino (Iceberg REST) | NO | Direct file access via API |\n",
    "\n",
    "**Configuration in Dremio:**\n",
    "\n",
    "1. **Add Source** → Iceberg / REST Catalog\n",
    "2. **Endpoint URI**: \n",
    "   ```\n",
    "   https://<workspace-url>/api/2.1/unity-catalog/iceberg-rest\n",
    "   ```\n",
    "3. **Warehouse** (= catalog name): `<uc-catalog-name>` e.g. `main`\n",
    "4. **Authentication**: Personal Access Token or OAuth2 (Service Principal)\n",
    "\n",
    "Unity Catalog uses **credential vending** - it passes temporary credentials to storage (S3/ADLS), so Dremio reads Parquet files directly.\n",
    "\n",
    "#### Manual Metadata Synchronization\n",
    "\n",
    "If Dremio doesn't see the latest data, force synchronization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7c8601-8257-4618-8321-0075d90fc270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Manual Iceberg metadata synchronization (if automatic didn't work)\n",
    "# spark.sql(f\"MSCK REPAIR TABLE {CATALOG}.{GOLD_SCHEMA}.dim_customer SYNC METADATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5dff20c-3ed5-41a6-bc58-76f97af84982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### UniForm Limitations for Dremio\n",
    "\n",
    "| Limitation | Description |\n",
    "|--------------|------|\n",
    "| Read-only | Dremio can only read, not write |\n",
    "| Deletion Vectors | Must be disabled (or use REORG) |\n",
    "| Materialized Views | Do not support UniForm |\n",
    "| Streaming Tables | Do not support UniForm |\n",
    "| VOID type | Not supported in Iceberg |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fea25469-cfdb-4f35-b3de-027387cd43b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Preparing a Dedicated View\n",
    "\n",
    "For BI tools (Dremio, Power BI), it is good practice to create views that hide join logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec4f0947-a72e-484f-be53-28566f9d7900",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a reporting view\n",
    "view_name = \"v_sales_summary_bi\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.{view_name} AS\n",
    "SELECT \n",
    "    c.country,\n",
    "    year(f.order_date) as year,\n",
    "    month(f.order_date) as month,\n",
    "    count(distinct f.order_id) as orders_count,\n",
    "    sum(f.total_amount) as total_revenue\n",
    "FROM {CATALOG}.{GOLD_SCHEMA}.fact_sales f\n",
    "JOIN {CATALOG}.{GOLD_SCHEMA}.dim_customer c ON f.customer_id = c.customer_id\n",
    "GROUP BY 1, 2, 3\n",
    "\"\"\")\n",
    "\n",
    "display(spark.createDataFrame([\n",
    "    (\"View\", view_name),\n",
    "    (\"Location\", f\"{CATALOG}.{GOLD_SCHEMA}.{view_name}\"),\n",
    "    (\"Status\", \"Ready for BI connection\")\n",
    "], [\"Parameter\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5f23285-d258-490a-b582-cfae92f234ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify view\n",
    "display(spark.table(f\"{CATALOG}.{GOLD_SCHEMA}.{view_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0de92d12-30ad-42c0-9ce6-b3a6a69fc551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "### BI Performance:\n",
    "- Use **Serverless SQL Warehouses** for best UX (fast start).\n",
    "- Enable **Photon** (default in Serverless/Pro).\n",
    "- Use **Materialized Views** for heavy aggregations if dashboards are slow.\n",
    "\n",
    "### Governance:\n",
    "- Do not connect BI directly to Silver/Bronze tables. Use **Gold** only.\n",
    "- Use dedicated **Service Principals** for BI connections, not personal accounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "371a586a-92af-4739-ba9f-fa43b89ce867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "1. We configured metadata for **Genie**.\n",
    "2. We discussed **SQL Warehouses** types.\n",
    "3. We prepared an optimized view for **Power BI / Dremio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0328f8c-b9b8-45cf-b892-9570f5b184e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2d5c92d-4523-467e-942c-866f20c6b9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{GOLD_SCHEMA}.{view_name}\")\n",
    "display(spark.createDataFrame([(\"Status\", \"Resources kept for further exercises\")], [\"Info\", \"Value\"]))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11_bi_analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
